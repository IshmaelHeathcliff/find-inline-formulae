\documentclass[12pt]{article}
\usepackage[SlantFont]{xeCJK}
\usepackage{fontspec}
\usepackage{cite}

\setCJKmainfont[BoldFont = SimHei]{SimSun}
\setCJKmonofont{SimSun}

\title{论文图片中定位公式位置}
\author{张浩然 1500010684}
\date{}

\begin{document}
\bibliographystyle{plain}

\maketitle
\tableofcontents

\abstract{}

\newpage

\section{背景介绍}
\noindent

现在的论文多以pdf格式或图片格式进行传播，在使用这些论文时，其中的公式部分往往是我们关心的地方，而快速找到并获取其中的公式就成了一项有意义的工作。我们在这里试图利用神经网络来解决论文图片中公式定位这个问题。

在处理论文图片中定位公式位置这个问题上，我们准备了两个方向上的方法。一是将论文图片切割为段落图片后使用目标检测方法来定位公式的位置，二是在预处理上更进一步将论文图片切割为单词图片，再将单词图片分类。

在目标检测这个问题上有许多的经典算法。基于卷积神经网络的目标检测开始于2013年RBG的论文\cite{rcnn}提出的RCNN。RCNN的算法过程大致为生成候选区域后使用CNN进行特征提取，将提取的特征通过SVM分类，最后通过边框回归(bounding-box regression)得到精确的目标区域。此算法的主要问题在于候选区域过多，大量的区域重复和无效造成了巨大的计算浪费。另一个问题在于使用CNN需要输入固定尺寸的图片，而图片的截取和拉伸等操作造成了输入信息的丢失。之后有许多算法以此为基础进行了改进。

首先是空间金字塔池化SPP-Net\cite{spp}，在全连接层前加入了一层将输入的特征图池化为特定尺寸的输出的特殊池化层，通过输入的尺寸与需要的输出尺寸计算出所需的池化核和步长从而实现了输出固定尺寸至全连接层。而之前的卷积层并不依赖于输入图片的尺寸，从而实现了任意尺寸的输入。实际上是将原图片多尺度采样输入带SPP层的CNN进行训练，也是被称为金字塔的原因。

之后RBG又提出了新的Fast-RCNN\cite{frcnn}，借鉴了SPP的思路提出了ROI池化层，以及将SVM分类改为使用softmax进行分类，并将分类和边框回归整合，不再独立进行训练。这个算法将除了候选框提取的所有步骤整合在一起进行训练，并引入类似SPP的池化层解决了不同尺寸的输入问题，使得训练过程大大提高了。

之后Faster-RCNN\cite{ftrcnn}又更进一步，提出了RPN解决了候选框提取的问题。RPN的特点在于不是在原图上进行候选框提取，而是在特征图上进行。原图通过CNN后首先在特征图上进行候选框提取，并将候选框进行分类，只将感兴趣的区域输入到ROI池化并进行下一步的分类学习。这样做可以让网络自己学习生成候选区域，大大减少选取候选区域的冗余，提高了预测时间，使得预测可以做到实时。至此候选框选取，CNN，ROI池化，分类与边框回归都整合到一起训练。

YOLO\cite{yolo}则使用了另外一个思路，直接将整个图像进行训练，不预先进行候选框提取。将整个图像分为$S \times S$的网格，物体的中心所在的网格负责该物体的检测，直接经过神经网络得到输出，输出包含物体位置、类别和置信度信息。YOLO全称为You Only Look Once，体现了该算法的简介和迅速。该算法相对于RCNN系列的算法拥有检测速度快和背景误检率低等优势，但在准确率和物体位置精度上较差。而且YOLO只在一个网格尺度上进行回归，缺乏多尺度信息，容易丢失小目标。

SSD\cite{ssd}在YOLO之上做了许多改进，采用了多尺度特征图的检测来适应不同大小的物体，最后的输出不是使用全连接层而是用卷积来取得检测结果，同时引入了Faster R-CNN中anchor的概念，设置不同长宽比和尺寸的先验框。这些改进使得SSD同时获得了较高的准确率和速度。

除了使用目标检测的方法，另一方面从单词切割入手，提前获得单词的位置，再将单词图片利用CNN分类。我在这个方向上自己写了具体的代码实现，下面对这个方法进行详细的叙述。



\section{数据处理}

\subsection{tex文件到图片}
\noindent

我们首先从网上获得了大量的论文tex文件，通过正则表达式找到其中被\$...\$框住的公式部分，由于我们的关注点只在于行内公式，故被\$\$...\$\$框住的行间公式部分需要排除，找到后在公式外加上可以框住公式的LaTeX命令，并分为使用红框和使用白框两个版本。使用白框的是我们进行训练的主要数据，红框版本是获得标记使用的。为了支持我们新增的LaTeX命令，仍需要使用正则表达式检测是否含有我们需要的宏包，若没有则在开头加上。接着将处理完毕的tex文件编译为pdf文件，在编译过程中发现大量的编译失败，主要原因一是使用的tex文件较为久远，主要为2001-2003年的数据，编译格式和使用的宏包各种各样，缺少相应的宏包支持，二是文件的编码格式不是utf-8，而编译时统一以utf-8为标准，故导致了读取失败。成功编译的pdf中也有少量缺失正文，只有公式存在。而且由于为了迅速编译，故所有文件只进行了一次编译，这样所有的引用都不会生效，参考文献的编号都变成了？，认为不影响本工作，所以忽略不需解决。

然后是将pdf文件转化为png图片。由于预计使用工具magick来进行转化，而为了全程使用python编程，故使用了magick的python包PythonMagick，而此包缺少文档说明，故一开始转化为png时遇到了困难，故一开始使用的是jpg格式。在查阅了许多解决方法后才终于得到了png文件，发现相同尺寸下png格式的图片只有jpg格式的几分之一，大大减小了硬盘占用，加快了数据传输。

以上方法都写在了文件texf\_topng.py中。宏包使用了re, os, pdflatex, PythonMagick, PyPDF2, 并导入了自己写的图片处理工具文件。re为使用正则表达式的宏包，pdflatex是将tex编译为pdf的宏包，PythonMagick是将pdf转化为png的宏包，PyPDF2是辅助pdf分页生成图片的宏包。在生成图片的同时裁去了图片的空白边框并通过生成的图片是否有红框来删去了不带公式的图片。单个tex文件处理使用文件ttp.py，批量文件处理使用ttpb.py。通过以上方法生成了红框版本和白框版本共计16万张图片，每张图片的生成速度在一秒以内，实际生成时使用并行处理。本方法由于还要将论文图片分割为单词，故实际使用的图片数没有这么多。

\subsection{数据预处理与单词分割}
\noindent

单词分割主要分为两个部分，文行分割与行内单词分割。以下处理均使用灰度图像。

在处理之前首先判断图片方向，认为一般只有正向和逆时针90度方向。由于灰度图像白色为255，黑色为0，故先将图片矩阵反转为白色为0，黑色为255，再分别求得图片矩阵的行和和列和。如果图象是正向的，空白边框也已经被截去，故认为行和中0的比例应大于列和中0的比例，因文行和文行之间有固定的空白，而单词与单词之间的空白位置每行不一。以此作为是否要将图片旋转的依据。此判断只对整页论文有效果，若进行单行或单个单词测试则无效，故设置为可以关闭。






\section{网络结构与算法}
\noindent

relu激活
conv1, pool1, conv2, pool2, spp, fc
阶梯衰减学习率
过拟合，正则化
滑动平均
spp
lrn
batch\_normalization 批标准化

sigmoid cross entropy loss

\cite{rcnn}
\cite{spp}
\cite{frcnn}
\cite{ftrcnn}
\cite{mrcnn}
\cite{yolo}
\cite{ssd}
\cite{ctpn}

\section{结果分析}

\section{改进}



\bibliography{ref.bib}
\end{document}
