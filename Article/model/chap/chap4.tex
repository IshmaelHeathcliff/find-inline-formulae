

\chapter{结果和展望}

本文首先从两个方向上给出了定位论文图片中公式位置的方法，其一是使用目标检测算法从段落图片中定位公式，其二是先进行单词分割，再将单词图片利用CNN分类，最后再利用单词图片位置信息还原。本文简述了目标检测的经典算法，然后详细实现了第二种方法，并对该方法进行了优化，使得结果很好。实现的具体步骤首先是进行数据的准备，我们的图片都是从latex源码经处理后编译为pdf再转化为png，生成的每张图片都有两个版本，白色框版本用来作为数据，红色框版本用来生成数据标注。在利用网络进行训练之前首先对论文图像进行预处理，即单词分割，包括文行分割和文行内单词分割两个步骤，都是利用空白来进行分割然后进行筛选。文行筛选最重要的指标是文行的前四分之一平均行和，辅助标准为平均行和和高度。单词分割则是主要利用空白的宽度经过最小二乘法得到单词间空白，注意要舍取最大的两个空白来得到更佳的效果。在参考了CPTN的方法后，将长单词图片分割为方形单词图片来保留更多的单词特征。单词分割完后就要生成数据库，由于单词图片和非单词图片之间的数量差距比较大，需要先进行采样处理，分别尝试了过采样和欠采样。采样完后生成tfrecords文件作为网络的输入。网络结构一开始采用了LeNet的7层结构，之后参考AlexNet和VGGNet进行了改进，结合自己的实际情况采用了10层的网络结构，卷积核都使用了小尺寸。网络中使用了多种优化算法，PReLu、指数衰减学习率、滑动平均、正则化、dropout、批标准化等。一共使用了三种方法生成数据来进行训练，一是过采样，一是欠采样，而是欠采样基础上使用方形单词分割。一开始使用了错误的标签来进行训练，结果过采样的效果非常差，但欠采样和方形单词分割仍能得到还不错的结果。使用正确的标签来进行训练后，三个方法的效果都变得非常好，数据结果上来看方形单词分割优于只欠采样优于过采样。虽然测试集的单词图片数有一两万张，但实际的论文图片只有47张，故通过实际比对各方法在实际论文图片上的效果，并和原本的带红框的原始标注进行对比，找出了错误的地方并进行了相应的分析。这个方法相比使用目标检测有许多显著的优点，一是精确度比较高，绝大多数检测对象都能够准确识别类别，且位置信息非常精确，因为是由实际单词分割给出位置而不是网络学习找出位置。另外网络结构简单，训练所需时间非常短。

尽管本文的在测试集上的效果已经非常显著，但仍有一些固有问题。如文行分割和单词分割不够精确，始终会有漏查单词或者检测多余的行间公式。另外有的单个单词图片难以辨别是否是公式，尤其是字母图片，缺乏上下文信息来进一步判断。若要进一步工作，试图使用更好的方法来区别文行和行间公式，如继续使用神经网络来学习文行和非文行的特征。要更精确地判断单词图片是否为公式，则可以尝试如CTPN中使用LSTM等RNN来获得序列信息，从而提高判断能力。



