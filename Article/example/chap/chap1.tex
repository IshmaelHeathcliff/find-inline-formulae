% Copyright (c) 2014,2016,2018 Casper Ti. Vector
% Public domain.

\chapter{背景介绍}

\noindent

现在的论文多以pdf格式或图片格式进行传播，在使用这些论文时，其中的公式部分往往是我们关心的地方，而快速找到并获取其中的公式就成了一项有意义的工作。我们在这里试图利用神经网络来解决论文图片中公式定位这个问题。

在处理论文图片中定位公式位置这个问题上，我们准备了两个方向上的方法。一是将论文图片切割为段落图片后使用目标检测方法来定位公式的位置，二是在预处理上更进一步将论文图片切割为单词图片，再将单词图片分类。

在目标检测这个问题上有许多的经典算法。基于卷积神经网络的目标检测开始于2013年RBG的论文\cite{rcnn}提出的RCNN。RCNN的算法过程大致为生成候选区域后使用CNN进行特征提取，将提取的特征通过SVM分类，最后通过边框回归(bounding-box regression)得到精确的目标区域。此算法的主要问题在于候选区域过多，大量的区域重复和无效造成了巨大的计算浪费。另一个问题在于使用CNN需要输入固定尺寸的图片，而图片的截取和拉伸等操作造成了输入信息的丢失。之后有许多算法以此为基础进行了改进。

首先是空间金字塔池化SPP-Net\cite{spp}，在全连接层前加入了一层将输入的特征图池化为特定尺寸的输出的特殊池化层，通过输入的尺寸与需要的输出尺寸计算出所需的池化核和步长从而实现了输出固定尺寸至全连接层。而之前的卷积层并不依赖于输入图片的尺寸，从而实现了任意尺寸的输入。实际上是将原图片多尺度采样输入带SPP层的CNN进行训练，也是被称为金字塔的原因。

之后RBG又提出了新的Fast-RCNN\cite{frcnn}，借鉴了SPP的思路提出了ROI池化层，以及将SVM分类改为使用softmax进行分类，并将分类和边框回归整合，不再独立进行训练。这个算法将除了候选框提取的所有步骤整合在一起进行训练，并引入类似SPP的池化层解决了不同尺寸的输入问题，使得训练过程大大提高了。

之后Faster-RCNN\cite{ftrcnn}又更进一步，提出了RPN解决了候选框提取的问题。RPN的特点在于不是在原图上进行候选框提取，而是在特征图上进行。原图通过CNN后首先在特征图上进行候选框提取，并将候选框进行分类，只将感兴趣的区域输入到ROI池化并进行下一步的分类学习。这样做可以让网络自己学习生成候选区域，大大减少选取候选区域的冗余，提高了预测时间，使得预测可以做到实时。至此候选框选取，CNN，ROI池化，分类与边框回归都整合到一起训练。

YOLO\cite{yolo}则使用了另外一个思路，直接将整个图像进行训练，不预先进行候选框提取。将整个图像分为$S \times S$的网格，物体的中心所在的网格负责该物体的检测，直接经过神经网络得到输出，输出包含物体位置、类别和置信度信息。YOLO全称为You Only Look Once，体现了该算法的简介和迅速。该算法相对于RCNN系列的算法拥有检测速度快和背景误检率低等优势，但在准确率和物体位置精度上较差。而且YOLO只在一个网格尺度上进行回归，缺乏多尺度信息，容易丢失小目标。

SSD\cite{ssd}在YOLO之上做了许多改进，采用了多尺度特征图的检测来适应不同大小的物体，最后的输出不是使用全连接层而是用卷积来取得检测结果，同时引入了Faster R-CNN中anchor的概念，设置不同长宽比和尺寸的先验框。这些改进使得SSD同时获得了较高的准确率和速度。

除了使用目标检测的方法，另一方面从单词切割入手，提前获得单词的位置，再将单词图片利用CNN分类。我在这个方向上自己写了具体的代码实现，下面对这个方法进行详细的叙述。
% vim:ts=4:sw=4
